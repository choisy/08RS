---
title: "08RS data"
number-sections: true
format:
  html:
    toc: true
    toc-depth: 4
editor: source
editor_options: 
  chunk_output_type: console
#bibliography: references.bib
#csl: the-american-naturalist.csl
---

```{r include = FALSE, eval = FALSE}
knitr::purl("data.qmd", "tmp.R", documentation = FALSE)
source("tmp.R")
file.remove("tmp.R")

add_nojekyll <- function() {
  file <- ".nojekyll"
  file.create(file)
  gert::git_add(file)
  gert::git_commit("Adding the .nojekyll file")
  gert::git_push()
}
```

```{r include = FALSE}
par2 <- function(...) par(..., mgp = c(1.5, .5, 0), bty = "n")

knitr::knit_hooks$set(
  margin1 = function(before, options, envir) {
    if (before) par2(plt = c(.105, .97, .15, .95)) else NULL
  })

eps <- 1
knitr::opts_chunk$set(margin1    = TRUE,
                      fig.retina = 2,
                      fig.align  = "center",
                      fig.height = eps * 5, # default is 5
                      fig.width  = eps * 7) # default is 7
```


## Global parameters

The path to the data folder on the local computer:

```{r}
root <- "~/Library/CloudStorage/OneDrive-OxfordUniversityClinicalResearchUnit/"
data_folder <- paste0(root, "GitHub/choisy/08RS/")
``` 


## Packages

Required packages:

```{r}
required <- c("readxl", "purrr", "dplyr", "magrittr", "tidyr", "anthro", "twang",
              "cobalt", "survey")
```

Installing those that are not installed yet:

```{r}
to_install <- required[! required %in% installed.packages()[,"Package"]]
if (length(to_install)) install.packages(to_install)
```

Loading some packages for interactive use:

```{r message = FALSE}
library(dplyr)
library(purrr)
library(stringr)
library(tidyr)
library(cobalt)
library(survey)
```


## Functions

A tuning of the `readxl::read_excel()` function:

```{r}
read_excel2 <- function(file, ...) readxl::read_excel(paste0(data_folder, file), ...)
```

A function that reads all the tabs of an excel file in the data folder `data_folder`
defined above:

```{r}
read_excel_file <- function(file) {
  sheets_names <- readxl::excel_sheets(paste0(data_folder, file))
  sheets_names |>
    map(~ read_excel2(file, .x)) |> 
    setNames(sheets_names)
}
```

A function that remove some slots of a list, by names:

```{r}
remove_slots <- function(lst, slt) {
  lst[setdiff(names(lst), slt)]
}
```

A function that extracts some variables of some slots of a list `x` of data frames:

```{r}
get_vars <- function(sel, x) {
  x |> 
    magrittr::extract(names(sel)) |>
    map2(sel, ~ select(.x, !!!.y))
}
```

The variables in questions are defined in the named list `sel` of character vectors.
The names of this list should be among the names of `x` and the character vectors of
each slots should be among the names of the columns of the data frames in the
corresponding slots. A function that patches data values from the data frame `patch`
into the data frame `df`, using the `key` variable as a common key between the two data
frames:

```{r}
patch <- function(patch, df, key) {
  ref <- df[, key]
  sel <- df[[key]] %in% patch[[key]]
  tmp <- df[sel, ]
  tmp_names <- names(tmp)
  tmp <- bind_cols(patch, tmp[, setdiff(tmp_names, names(patch))])[tmp_names]
  df[! sel, ] |> 
    bind_rows(tmp) |> 
    left_join(x = ref, y = _, by = key)
}
```

A function that renames a column of a data frame:

```{r}
rename2 <- function(df, newname, oldname) {
  df_names <- names(df)
  df_names[which(df_names == oldname)] <- newname
  setNames(df, df_names)
}
```

A function that splits a data frame into a list of data frames:

```{r}
split_df <- function(x, n_rows) {
  nb_rows <- nrow(x)
  split(x, gl(nb_rows %/% n_rows + (nb_rows %% n_rows > 0), n_rows, nb_rows))
}
```

A function that appends a data frame `x` with `n` rows of values `v`:

```{r}
append_dataframe <- function(x, n = 1, v = 0) {
  1:ncol(x) |>
    map(~ rep(v, n)) |> 
    as.data.frame() |> 
    setNames(names(x)) |>  
    (\(y) bind_rows(x, y))()
}
```

A function that applies `append_dataframe()` to the last slot of a list `x` of data
frame so that the number of rows of the data frame in the last slot is equal to the
number of rows of the data frame in the first lost:

```{r}
append_last <- function(x, v = 1) {
  nb_slots <- length(x)
  nb_rows1 <- nrow(x[[1]])
  nb_rows2 <- nrow(x[[nb_slots]])
  if (nb_rows2 < nb_rows1) {
    x[[nb_slots]] <- append_dataframe(x[[nb_slots]], nb_rows1 - nb_rows2, v)
  }
  x
}
```

A tuning of the `image()` function:

```{r}
image2 <- function(x, y, z, ...) image(x, y, t(z[nrow(z):1, ]), ...)
```

A function that adds a zero y value to both ends of a data frame with two columns `x`
and `y`:

```{r}
adding_zero_ys <- function(x) {
  x <- as_tibble(x[c("x", "y")])
  x <- bind_rows(head(x, 1), x, tail(x, 1))
  x$y[c(1, nrow(x))] <- 0
  x
}
```

A function that converts a 1-row matrix with columns names into a named vector:

```{r}
as_vector <- function(x) setNames(as.vector(x), colnames(x))
```

A tuning of the `coef()` function:

```{r}
coef2 <- function(x) last(coef(x))
```

A tuning of the `confint()` function:

```{r}
confint2 <- function(x) as_vector(last(suppressMessages(confint(x))))
```

A function that retrieve the p value of the last parameter of a model:

```{r}
get_p <- function(x) last(as.vector(coefficients(summary(x))))
```


## 08RS CRF data

Loading the data from CliRes:

```{r}
CRF08RS <- read_excel_file("6-11-2024-CTU08RS_Data.xlsx")
```

The names of the data frames in CliRes and in Saras' code, with definitions:

```{r}
# CliRes        Saras           Definition
# ------------------------------------------------------------------
# ENROL         data_EN         enrollment
# HIST          data_HIST       history at enrollment
# CONHIST       CONHIST         contact history at enrollment
# EXAM          data_EX         symptoms and signs at enrollment
# LAB           data_LAB        lab results at admission
# NEU           data_NEU        neurological exam
# DAILY         data_Daily      daily review
# MED           data_MED        medications
# DEVSOCSED     data_DEV        development and socio-economic data
# DISC          data_DISC       discharge summary
# FUP           data_FUP        first follow-up day 7-10
# FUP_II        data_FUP6m      first follow-up month 6
# FUP_III       data_FUP18m     first follow-up month 18
# NEURO         data_NEURO      neurological assessment
# ABC           data_MABC       movement ABC-2
```

The 08RS CRF dictionary:

```{r}
CRF_dict <- list(
  devsocsed = list(MomEdu = c("Never been to school",
                              "Attended some primary school",
                              "Completed primary school (5th gr)",
                              "Completed lower secondary school (9th gr)",
                              "Completed higher secondary school (12th gr)",
                              "Completed university/college degree",
                              "Completed postgraduate degree"),
                   Toilet = c("Own flush toilet",
                              "Shared flush toilet",
                              "Traditional pit toilet",
                              "Ventilation improved pit toilet",
                              "No facility/bush/field",
                              "None of above"),
                   Water  = c("Private tap",
                              "Public standpipe",
                              "Bottled water",
                              "Well in own residence",
                              "Public well",
                              "Rain water",
                              "Spring",
                              "River/lake/pond", NA,
                              "None of the above")),
  disc = list(GradeHFMD   = c("grade 1",
                              "grade 2a",
                              "grade 2b(1)",
                              "grade 2b(2)",
                              "grade 3",
                              "grade 4",
                              "Not Applicable"),
              Outcome     = c("Full recovery without complication",
                              "Incomplete recovery",
                              "Transferred to another hospital",
                              "Taken home without approval",
                              "Death",
                              "Discharged to die")))
```

Selection of variables from the 08RS CRF:

```{r}
selection08RS <- list(ENROL     = c("ParNo", "DateEnrol", "Gender", "DateBirth"),
                      HIST      = c("ParNo", "DateIllness", "DateAdmHTD", "DateAdmHTD",
                                    "DateAdmHosp", "HFMDToday", "HFMDAdmitted"),
                      EXAM      = c("ParNo", "headCircumference", "height", "weigh"),
                      DEVSOCSED = c("ParNo", "MomEdu", "Toilet", "Refrigerator",
                                    "AirConditioner", "Motorbike", "Water"),
                      DISC      = c("ParNo", "DateDisc", "GradeHFMD", "TreatSepsis",
                                    "Outcome", "Seizure", "Hypertonicity", "LimbPara",
                                    "CNP", "DiapWeak", "Trache", "Nasotube",
                                    "BehaveChange"))
```


## 02EI CRF data

```{r}
CRF02EI <- read_excel_file("6-11-2024-CTU02EI_Data.xlsx")
```

Selection of variables from the 02EI CRF:

```{r}
selection02EI <- list(Demo  = c("studyCode", "height", "weight"),
                      Hist  = c("studyCode", "IllnessDate"),
                      Disch = c("studyCode", "seizures", "tracheostomy",
                                "muscleStength", "limbParalysing", "nerveParalysing"))
```


## PCR data

```{r message = FALSE}
PCR <- "03EI-08RS PCR-Seq result.xlsx" |>
  read_excel2("08RS") |> 
  select(ID, `OUCRU RESULT`) |> 
  mutate(across(ID, as.numeric)) |> 
  na.exclude()
```


## MRI data

```{r, message = FALSE}
MRI <- paste0(root, "GitHub/choisy/08RS/part_dataMRIentry_28AUG15_errorcor.csv") |>
  readr::read_csv() |> 
  rename(ID = code) |> 
  select(ID, Final, Acute) |> 
  mutate(across(c("Final", "Acute"), ~ .x == "Yes"))
```

What is the difference between `Final` and `Acute`?

```{r}
filter(MRI, Final != Acute)
```


## Children data

### 08RS, PCR, MRI

The case and control groups:

```{r}
groups <- c(rep("HFMD", 299), rep("control", 200),
            rep("HFMD", 200), rep("control", 299))
```

First recoding of variables:

```{r}
recoding1 <- function(x) {
  x |>
    mutate(across(Gender, ~ c("male", "female")[.x]),
           across(starts_with("Date"), as.Date),
           across(c("Refrigerator", "AirConditioner",
                    "Motorbike", "TreatSepsis"), ~ .x < 2))
}
```

Second recoding of variables:

```{r}
recoding2 <- function(x) {
  x |>
    mutate(across(HFMD, ~ CRF_dict$disc$GradeHFMD[.x]),
           across(MomEdu, ~ CRF_dict$devsocsed$MomEdu[.x]),
           across(Toilet, ~ CRF_dict$devsocsed$Toilet[.x]),
           across(Water, ~ CRF_dict$devsocsed$Water[.x]),
           across(Outcome, ~ CRF_dict$disc$Outcome[.x]))
}
```

Selecting and recoding the variables from the 08RS CRF, and assigning to case or
control:

```{r}
children <- selection08RS |> 
  remove_slots("ABC") |> 
  get_vars(CRF08RS) |> 
  reduce(left_join, by = "ParNo") |> 
  rowwise() |> 
  mutate(HFMD = max(across(c(HFMDToday, HFMDAdmitted, GradeHFMD)))) |> #takes max grade
  ungroup() |> 
  recoding1() |> 
  recoding2() |>
  mutate(ID    = as.numeric(str_remove(ParNo, "^.*-")),
         group = groups[ID]) |> 
  left_join(MRI, "ID") |> 
  left_join(PCR, "ID") |> 
  rename(PCR = `OUCRU RESULT`) |> 
  select(-HFMDToday, -HFMDAdmitted, -GradeHFMD, -ID) |> 
  select(ParNo, Gender, DateBirth, DateIllness, DateAdmHosp,
         DateAdmHTD, DateEnrol, DateDisc, everything()) |> 
  arrange(ParNo)
```

### Patching 02EI CRF

Conversion of IDs between 02EI and 08RS:

```{r}
(ID_conv <- tibble(s02EI = paste0("03-0", c(paste0("0", c(1, 3:9)), c("11", "13"))),
                   s08RS = paste0("03-0", c(43, 52:56, 60, 62, 78, 79))))
```

Patching the data values from the 02EI CRF:

```{r}
children <- selection02EI |> 
  get_vars(CRF02EI) |> 
  reduce(left_join, by = "studyCode") |> 
  mutate(across(IllnessDate, as.Date),
         across(c("seizures", "tracheostomy", "muscleStength", "limbParalysing",
                  "nerveParalysing"), ~ .x < 2)) |> 
  rename(ParNo         = studyCode,
         weigh         = weight,
         DateIllness   = IllnessDate,
         Seizure       = seizures,
         Trache        = tracheostomy,
         Hypertonicity = muscleStength,
         LimbPara      = limbParalysing,
         CNP           = nerveParalysing) |> 
  filter(ParNo %in% ID_conv$s02EI) |> 
  mutate(across(ParNo, ~ unname(with(ID_conv, setNames(s08RS, s02EI))[.x]))) |> 
  patch(children, "ParNo")
```

### Stunt and waste

```{r}
children <- children |> 
  mutate(age = DateEnrol - DateBirth,
         z   = anthro::anthro_zscores(c(male = 1, female = 2)[Gender],
                                      as.numeric(age),
                                      weight = weigh,
                                      lenhei = height)[c("zlen", "zwfl")]) |> 
  unnest(z) |> 
  mutate(stunting = zlen < -2,
         wasting  = ifelse(zwfl < -3, "severe",
                           ifelse(zwfl < -2, "moderate", "no"))) |> 
  select(- zlen, - zwfl)
```

### Missing values

```{r}
n <- nrow(children)

children |> 
  select(- group) |> 
  map_dfr(~ sum(is.na(.x))) |> 
  pivot_longer(! ParNo, names_to = "variable", values_to = "number_of_NA") |> 
  mutate(percentage_of_NA = round(100 * number_of_NA / n)) |> 
  select(- ParNo) |>
  print(n = Inf)
```


## M-ABC data

```{r}
ABC <- CRF08RS$ABC |> 
  select(ParNo, DateTested, ends_with("ISS")) |> 
  mutate(across(starts_with("Date"), as.Date)) |> 
  arrange(ParNo, DateTested)
```

Of note, here

* `MD` stands for manual dexterity,
* `AC` stands for aiming and catching and
* `BAL` stands for balance.

```{r}
ABC |> 
  na.exclude()
```


## Bayley data

Loading the data from CliRes:

```{r}
Bayley0 <- read_excel_file("12-9-2025-Bayley_v3_P1_Data.xlsx")
```

The tabs that we are interested in are the following:

* **CS:** cognitive scale
* **RC:** receptive communication (language scale)
* **EC:** expressive communication (language scale)
* **FM:** fine motor (motor scale)
* **GM:** gross motor (motor scale)

```{r}
Bayley_tabs <- c("CS", "RC", "EC", "FM", "GM")
```

Let's generate the data frame from these tabs:

```{r}
common_variables1 <- c("PARNO", "DATETESTED")
common_variables2 <- c(common_variables1, "SCALESCORE")

Bayley<- Bayley_tabs |> 
  map(~ c(common_variables2, .x)) |> 
  setNames(Bayley_tabs) |> 
  get_vars(Bayley0) |> 
  map2(paste0("SCALESCORE_", Bayley_tabs), rename2, "SCALESCORE") |> 
  reduce(left_join, by = c("PARNO", "DATETESTED")) |> 
  mutate(across(starts_with("DATE"), as.Date)) |> 
  rename(ParNo = PARNO) |> 
  mutate(across(ParNo, ~ stringr::str_remove(.x, "08RS_")))
```


## Saras' CSV file

```{r, message = FALSE}
saras <- readr::read_csv(paste0(root, "GitHub/choisy/08RS/complete data including all withdrawals_updated26_3_21.csv"))
```

```{r}
select(saras, waste, visitM, ddifENB, ddifEN, FUP, FUP1)
```

```{r}
table(saras$waste)
```


## Time points

A function that generates the time points:

```{r}
make_time_points <- function(x) {
  children |> 
    select(ParNo, DateEnrol, DateDisc) |> 
    left_join(x, "ParNo") |> 
    mutate(time_diff = DateTested - DateEnrol,
           time1 = 0, time2 = 6, time3 = 18, # in months
           across(c(time1, time2, time3), ~ as.numeric(abs(time_diff - 30 * .x)))) |> 
    rowwise() |> 
    mutate(min_delay = min(across(c(time1, time2, time3)))) |> 
    ungroup() |> 
    mutate(time_point = ifelse(min_delay == time1,
                               "enrollment", ifelse(min_delay == time2,
                                                    "6 months", "18 months")))
}
```

A function that gets the IDs of children with duplicated assessments:

```{r}
get_IDs_with_duplicated <- function(x) {
  x |> 
    filter(! is.na(time_point)) |> 
    group_by(ParNo) |> 
    group_modify(~ .x |>
                   group_by(time_point) |>
                   tally()) |> 
    ungroup() |> 
    filter(n > 1) |> 
    pull(ParNo) |> 
    unique()
}
```

A function that uses the previous two to generate the data with duplicated assessments:

```{r}
show_duplicated_assessments <- function(x) {
  data_with_time_points <- make_time_points(x)
  IDs_with_duplicates <- get_IDs_with_duplicated(data_with_time_points)
  filter(data_with_time_points, ParNo %in% IDs_with_duplicates)
}
```


### M-ABC data

```{r}
ABC |>
  show_duplicated_assessments() |> 
  writexl::write_xlsx("M-ABC2.xlsx")
```

Here all the duplicates are complete. We'll simply keep all the earlier ones:

```{r}
ABC2 <- ABC |> 
  make_time_points() |>
  arrange(ParNo, time_point, min_delay) |> 
  group_by(ParNo, time_point) |> 
  group_modify(~ head(.x, 1)) |> 
  ungroup() |> 
  select(-DateEnrol, -DateDisc, -min_delay, - time_diff, -time1, -time2, -time3) |> 
  rename(Date_ABC = DateTested)
```


### Bayley data

```{r}
Bayley <- rename(Bayley, DateTested = DATETESTED)

Bayley |>
  show_duplicated_assessments() |> 
  writexl::write_xlsx("Bayley2.xlsx")
```

This shows that

* there is one and only one complete measurement per time point
* the complete measurement is always the earlier one, except for patient `03-514`

In consequence, we decide to simply filter out all the incomplete duplicates:

```{r}
Bayley2 <- Bayley |> 
  make_time_points() |>
  group_by(ParNo, time_point) |> 
  group_modify(~ {if (nrow(.x) > 1) return(na.exclude(.x)); .x }) |> 
  ungroup() |> 
  select(-DateEnrol, -DateDisc, -min_delay, - time_diff, -time1, -time2, -time3) |> 
  rename(Date_Bayley = DateTested)
```


### Merging

Merging the M-ABC and Bayley data:

```{r}
followups <- full_join(ABC2, Bayley2, c("ParNo", "time_point"))
```


### Visualization

A function that prepend all the data frames of a list `x` of data frames with `n`
columns of the `v` values:

```{r}
prepend_white <- function(x, n, v) {
  nbrows <- nrow(x[[1]])
  white_space <- v |> 
    rep(n * nbrows) |> 
    matrix(nbrows) |> 
    as.data.frame()
  map(x, ~ cbind(white_space, .x))
}
```

A function that (i) splits the data frame `x` into a list of data frame of `n` rows 
(except possibly for the last slot), (ii) prepends each of these data frames with `wc`
columns of 1s, and (iii) concatenate all these data frames side by side into a matrix:

```{r}
side_by_side <- function(x, n, wc) {
  x |>
    select(-ParNo) |>
    split_df(n) |> 
    append_last() |>
    prepend_white(wc, 1) |> 
    reduce(cbind) |> 
    as.matrix()
}
```

A tuning of `image2()`:

```{r}
image3 <- function(x, col_no, col_yes) {
  image2(0:ncol(x), 0:nrow(x), x, axes = FALSE, ann = FALSE, col = c(col_no, col_yes))
}
```

The function that plots the heatmap:

```{r}
heatmap2 <- function(x, nbrow = 45, nb_wc = 2,
                     col_Bayley = adjustcolor("red", .3),
                     col_ABC    = adjustcolor("blue", .3),
                     col_NA     = adjustcolor("white", 0),
                     col_lines  = "white") {
# plotting M-ABC data:
  tmp <- x |> 
    select(-Date_Bayley) |> 
    pivot_wider(names_from = time_point, values_from = Date_ABC) |> 
    side_by_side(nbrow, nb_wc)
  image3(tmp, col_NA, col_Bayley)
  
# adding Bayley data:
  par(new = TRUE)
  x |> 
    select(-Date_ABC) |> 
    pivot_wider(names_from = time_point, values_from = Date_Bayley) |> 
    side_by_side(nbrow, nb_wc) |> 
    image3(col_NA, col_ABC)

# adding separation lines:
  abline(v = 0:ncol(tmp), col = col_lines)
  abline(h = 0:nbrow, col = col_lines)

# adding children IDs:
  ids <- str_remove(unique(x$ParNo), "^.*-")
  sel <- 1:length(ids)
  by <- 3 + nb_wc
  ncol_tmp <- ncol(tmp)
  nbcol <- ncol_tmp / by
  xs <- rep(seq(1, ncol_tmp, by), each = nbrow)[sel]
  ys <- rep(rev(1:nbrow - .5), nbcol)[sel]
  text(xs, ys, ids)

# adding time points:
  xx <- seq(1 + nb_wc, ncol_tmp, by) - .5
  mtext(rep(c("e", "1", "2"), nbcol)[sel], at = sort(c(xx, xx + 1, xx + 2)))
}
```

An overview of the M-ABC and Bayley data for all the children and the 3 time points:

```{r fig_followup_data_availability, fig.height = 11, fig.width  = 14}
expand_grid(ParNo      = unique(followups$ParNo),
            time_point = c("enrollment", "6 months", "18 months")) |> 
  left_join(followups, c("ParNo", "time_point")) |> 
  select(ParNo, time_point, starts_with("Date")) |> 
  mutate(across(starts_with("Date"), ~ as.numeric(! is.na(.x)) + 1)) |> 
  heatmap2()
```

where blue is where the Bayley data are available, red is where the M-ABC data are
available, purple is where both data are available and white is where none of the data
are available.


## Analysis

### HFMD vs controls

From here we work with 2 data frames: `children` that contains the children
information, and `followups` that contains the follow-up data. Note that height and
weight (and consequently stunting) is missing for about 22% of children:

```{r}
children |> 
  select(group, age, MomEdu, Gender, stunting) |> 
  map_int(~ sum(is.na(.x)))
```

Some common code:

```{r}
cols <- c(2, 4)
adjcol <- function(...) adjustcolor(..., alpha = .3)

barplot2 <- function(height, x) {
  barplot(height, names.arg = x, beside = TRUE, ylab = "proportion",
          col = adjcol(rev(cols)))
}

add_legend <- function(where = "topright") {
  legend(where, legend = c("control", "HFMD"), fill = adjcol(rev(cols)), bty = "n")
}
```

Let's look at the age distribution of the controls and HFMD cases:

```{r fig_age_distribution}
tmp <- children |>
  mutate(across(age, ~ as.numeric(.x) / 30)) |> 
  group_by(group) |> 
  group_map(~ .x |> pull(age) |> density(from = 0))

tmp |> 
  map(~ .x |> unclass() |> magrittr::extract(c("x", "y")) |> as_tibble()) |> 
  bind_rows() |> 
  map(range) |> 
  with(plot(NA, xlim = x, ylim = y, xlab = "age (months)", ylab = "density"))

tmp |> 
  walk2(cols, ~ polygon(adding_zero_ys(.x), col = adjcol(.y), border = NA))

add_legend()
```

Let's now look at the level of the mother's education:

```{r fig_mom_edu}
edu_order <- c("Never been to school", "Attended some primary school",
               "Completed primary school (5th gr)",
               "Completed lower secondary school (9th gr)",
               "Completed higher secondary school (12th gr)",
               "Completed university/college degree", "Completed postgraduate degree")

children |> 
  with(table(MomEdu, group)) |>
  prop.table(2) %>%
  `[`(edu_order, ) |> 
  t() |> 
  barplot2(c("none", "some", "5th grd", "9th grd", "12th grd", "college", "postgrad"))

add_legend()
```

Stunt and gender:

```{r fig_sex_stunt}
children |> 
  select(group, Gender, stunting) |> 
  na.exclude() |> 
  group_by(group) |> 
  group_split() |> 
  map(~ .x |> group_by(Gender, stunting) |> tally() |> ungroup()) |> 
  reduce(left_join, c("Gender", "stunting")) |> 
  select(starts_with("n")) |> 
  as.matrix() |> 
  prop.table(2) |> 
  t() %>%
  `[`(2:1, ) |> 
  barplot2(rep(c("female", "male"), each = 2))

mtext(rep(c("non-stunt", "stunt"), 2), 1, 1.5, at = c(2, 5, 8, 11))
add_legend()
```

### Propensity scores

The covariables:

```{r}
covariables <- select(children, ParNo, Gender, age, MomEdu, stunting, group)
```

The formula:

```{r}
ps_formula <- group ~ Gender + age + MomEdu + stunting
```

A function that generates a data set for a given response variable at a given time
point:

```{r}
make_data <- function(response, timepoint) {
  followups |> 
    filter(time_point == timepoint) |> 
    select(ParNo, all_of(response)) |> 
    na.exclude() |> 
    left_join(covariables, "ParNo") |> 
    select(-ParNo) |> 
    select(all_of(response), group, everything()) |> 
    na.exclude()
}
```

Making the data for FM at enrollment:

```{r}
FM_data_enrollment <- make_data("FM", "enrollment")
```

#### Logistic regression

The function that generates the propensity scores from a logistic regression:

```{r}
logistic_ps <- function(data, formula) {
  data |>
    mutate(across(group, ~ .x == "HFMD")) |> 
    glm(formula, binomial, data = _) |> 
    predict(type = "response")
}
```

Let's compute the propensity scores and the weights:

```{r}
FM_data_enrollment2 <- FM_data_enrollment |>
  mutate(#across(group, ~ .x == "HFMD"),
         ps = logistic_ps(pick(everything()), ps_formula),
         ow = ifelse(group, 1 - ps, ps))
```

Diagnostic:

```{r}
FM_data_enrollment2 |>
  bal.tab(ps_formula, data = _, s.d.denom = "treated", weights = "ow", un = TRUE) |> 
  love.plot(stars = "std", abs = TRUE, thresholds = c(m = .1))
```

The treatment effect:

```{r}
fit_model <- FM_data_enrollment2 |> 
  svydesign(ids = ~1, weights = ~ow, data = _) |> 
  svyglm(FM ~ group, design = _)

map(list(summary, coef, confint), ~ .x(fit_model))
```

Pipeline:

```{r}
ps_formula <- group ~ Gender + age + MomEdu + stunting

lr_ps <- expand_grid(response  = c("MD1ISS", "MD2ISS", "MD3ISS", "AC1ISS", "AC2ISS",
                                   "BAL1ISS", "BAL2ISS", "BAL3ISS",
                                   "CS", "RC", "EC", "FM", "GM"),
                     timepoint = c("enrollment", "6 months", "18 months")) |> 
  mutate(dataset = map2(response, timepoint, ~ make_data(.x, .y)),
         ctable  = map(dataset, ~ .x |>
                         pull(group) |>
                         table() |>
                         as.vector())) |> 
  filter(map_lgl(ctable, ~ length(.x) > 1)) |> 
  mutate(ctable = map(ctable, ~ setNames(.x, c("control", "HFMD")))) |> 
  unnest_wider(ctable) |> 
  filter(HFMD > 3) |> 
  mutate(dataset = map(dataset,
                       \(x) mutate(x, across(group, \(y) y == "HFMD"),
                                      ps = logistic_ps(pick(everything()), ps_formula),
                                      ow = ifelse(group, 1 - ps, ps))),
         balance = map(dataset, ~ bal.tab(ps_formula, data = .x, s.d.denom = "treated",
                                          weights = "ow", un = TRUE)),
         max_diff = map_dbl(balance, ~ max(.x$Balance$Diff.Adj)),
         pass = max_diff < .1,
         formula = map(response, ~ reformulate("group", .x)),
         model0 = map2(formula, dataset, ~ glm(.x, data = .y)),
         model1 = map2(response, dataset,
                       ~ glm(reformulate(c("Gender", "age", "MomEdu", "stunting",
                                           "group"), .x), data = .y)),
         model2 = map2(formula, dataset, ~ .y |>
                       svydesign(ids = ~1, weights = ~ow, data = _) |> 
                       svyglm(.x, design = _)),
         coef0 = map_dbl(model0, coef2),
         ci = map(model0, confint2)) |>   
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "0"), ends_with("%")) |> 
  mutate(p0 = map_dbl(model0, get_p),
         coef1 = map_dbl(model1, coef2),
         ci = map(model1, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "1"), ends_with("%")) |> 
  mutate(p1 = map_dbl(model1, get_p),
         coef2 = map_dbl(model2, coef2),
         ci = map(model2, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "2"), ends_with("%")) |> 
  mutate(p2 = map_dbl(model2, get_p))
```

Which gives:

```{r}
lr_ps |> 
  select(response, timepoint, control, HFMD, max_diff, ends_with("2"), -model2) |> 
  print(n = Inf)
```

Let's compare with the results without propensity scores:

```{r}
lr_ps |> 
  select(response, timepoint, starts_with("coef"), starts_with("p"), -pass) |> 
  print(n = Inf)
```

#### Take 2

```{r}
logistic_ps <- function(data) {
  data |>
    mutate(across(group, ~ .x == "HFMD")) |> 
    glm(ps_formula, binomial, data = _) |> 
    predict(type = "response")
}
```

```{r}
twang_ps <- function(data, ...) {
  data |> 
    mutate(across(group, ~ as.integer(group == "HFMD")),
           across(where(~ is.character(.x) | is.logical(.x)), as.factor),
           across(age, as.numeric)) |> 
    as.data.frame() |> 
    ps(ps_formula, data = _, estimand = "ATT", stop.method = "es.mean",
       verbose = FALSE, ...) |> 
    get.weights("es.mean")  
}
```

```{r}
svyglm2 <- function(formula, data, w) {
  data |>
    svydesign(ids = ~1, weights = w, data = _) |> 
    svyglm(formula, design = _)
}
```

```{r}
bal_tab <- function(data, w) {
  data |> 
    mutate(across(group, ~ .x == "HFMD")) |> 
    bal.tab(ps_formula, data = _, weights = w, s.d.denom = "treated", un = TRUE)
}
```

```{r}
get_diff <- function(x) x$Balance$Diff.Adj
```

```{r}
get_max_diff <- function(data, w) {
  data |> 
    bal_tab(w) |> 
    get_diff() |> 
    max()
}
```

```{r}
reformulate2 <- function(x) {
  reformulate(c("Gender", "age", "MomEdu", "stunting", "group"), x)
}
```



```{r}
lr_ps <- expand_grid(response  = c("MD1ISS", "MD2ISS", "MD3ISS", "AC1ISS", "AC2ISS",
                                   "BAL1ISS", "BAL2ISS", "BAL3ISS",
                                   "CS", "RC", "EC", "FM", "GM"),
                     timepoint = c("enrollment", "6 months", "18 months")) |> 
  mutate(dataset = map2(response, timepoint, ~ make_data(.x, .y)),
         ctable  = map(dataset, ~ as.vector(table(.x$group)))) |> 
  filter(map_lgl(ctable, ~ length(.x) > 1)) |> 
  mutate(ctable = map(ctable, ~ setNames(.x, c("control", "HFMD")))) |> 
  unnest_wider(ctable) |> 
  filter(HFMD > 3) |> 
  mutate(dataset = map(dataset,
                       ~ mutate(.x, ps = logistic_ps(pick(everything())),
                                    ow = ifelse(group == "HFMD", 1 - ps, ps),
                                    tw = twang_ps(pick(everything())),
                                    t2 = twang_ps(pick(everything()), 
                                                  n.trees = 5000,
                                                  interaction.depth = 2))),
         mdifow = map_dbl(dataset, get_max_diff, "ow"),
         mdiftw = map_dbl(dataset, get_max_diff, "tw"),
         mdift2 = map_dbl(dataset, get_max_diff, "t2"),
         formula = map(response, ~ reformulate("group", .x)),
         glm0 = map2(formula, dataset, ~ glm(.x, data = .y)),
         glm1 = map2(response, dataset, ~ glm(reformulate2(.x), data = .y)),
         m_ow = map2(formula, dataset, ~ svyglm2(.x, .y, ~ow)),
         m_tw = map2(formula, dataset, ~ svyglm2(.x, .y, ~tw)),
         m_t2 = map2(formula, dataset, ~ svyglm2(.x, .y, ~t2)),
         cf_l0 = map_dbl(glm0, coef2),
         ci = map(glm0, confint2)) |>   
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "l0"), ends_with("%")) |> 
  mutate(p_l0 = map_dbl(glm0, get_p),
         cf_l1 = map_dbl(glm1, coef2),
         ci = map(glm1, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "l1"), ends_with("%")) |> 
  mutate(p_l1 = map_dbl(glm1, get_p),
         cf_ow = map_dbl(m_ow, coef2),
         ci = map(m_ow, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "ow"), ends_with("%")) |> 
  mutate(p_ow = map_dbl(m_ow, get_p),
         cf_tw = map_dbl(m_tw, coef2),
         ci = map(m_tw, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "tw"), ends_with("%")) |> 
  mutate(p_tw = map_dbl(m_tw, get_p),
         cf_t2 = map_dbl(m_t2, coef2),
         ci = map(m_t2, confint2)) |> 
  unnest_wider(ci) |> 
  rename_with(~ paste0(.x, "t2"), ends_with("%")) |> 
  mutate(p_t2 = map_dbl(m_t2, get_p))  
```




#### TWANG

```{r}
library(twang)

lr_ps$dataset[[1]] |> 
  mutate(across(group, ~ as.integer(group == "HFMD")),
         across(where(~ is.character(.x) | is.logical(.x)), as.factor),
         across(age, as.numeric)) |> 
  as.data.frame() |> 
  ps(ps_formula, data = _, estimand = "ATT", stop.method = "es.mean") |> 
  get.weights("es.mean")
```


#### TMLE

```{r}
#libs <- c("SL.glm", "SL.glmnet", "SL.mean") # "SL.gam", "SL.ranger"
#libs <- c("SL.glm", "SL.glmnet", "SL.mean", "SL.gam", "SL.ranger")
libs <- c("SL.glm", "SL.glmnet", "SL.mean", "SL.gam")
libs <- c("SL.glm", "SL.glmnet", "SL.gam")

tmle2 <- function(data, response, family = "gaussian", ...) {
  out <- data |> 
    select(Gender, age, MomEdu, stunting) |> 
    mutate(across(where(~ is.character(.x) | is.logical(.x)), as.factor),
           across(age, as.numeric)) |>
    tmle(data[[response]], as.integer(data$group == "HFMD"), W = _, family = family,
         Q.SL.library = libs, g.SL.library = libs)
  unlist(out$estimates$ATT[c("psi", "CI", "pvalue")])
}

tmle2(FM_data_enrollment, "FM")
```

        psi         CI1         CI2      pvalue 
1.037064873 0.356031919 1.718097828 0.002839509 

       psi        CI1        CI2     pvalue 
-0.1563582 -0.7466466  0.4339302  0.6036463

```{r}
# 0) Install packages if you don't have them (run once)
# install.packages(c("tmle", "SuperLearner", "glmnet", "mgcv")) 
# SuperLearner package will automatically use wrappers available; glmnet/mgcv recommended for better learners.

library(tmle)
library(SuperLearner)

# 1) Prepare your data frame (assume it's called df)
# Ensure variable names and types:
# df$FM       : positive integer outcome
# df$group    : "cases" / "control" (character or factor)
# df$Gender   : binary (e.g. "M"/"F" or 0/1)
# df$age      : numeric
# df$MomEdu   : factor with 6 levels
# df$stunting : binary (0/1 or "yes"/"no")

# Example checks / conversions:
df$group <- factor(df$group, levels = c("control", "HFMD"))  # ensure "control" is reference
# convert binary char to 0/1 if necessary:
if(is.character(df$stunting) || is.factor(df$stunting)) {
  # adapt mapping if needed; here assume "no"/"yes" or "0"/"1"
  df$stunting <- as.numeric(as.character(df$stunting))
}
if(is.character(df$Gender) || is.factor(df$Gender)) {
  # map to 0/1 (example: Female = 0, Male = 1) — adapt to your coding
  df$Gender <- as.numeric(df$Gender == "M") 
}

# 2) Define outcome Y, treatment A, covariates W
Y <- df$FM
A <- as.numeric(df$group == "HFMD")  # A = 1 for cases, 0 for control
W <- df[, c("Gender", "age", "MomEdu", "stunting")]

# 3) Choose SuperLearner libraries (simple example)
# You can change/add libraries depending on installed wrappers:
Qlib <- c("SL.glm", "SL.glmnet", "SL.mean")   # outcome regressions
glib <- c("SL.glm", "SL.glmnet", "SL.mean")  # propensity score regressions

# -----------------------------
# Option A: TMLE treating FM as continuous (Gaussian)
# -----------------------------
tmle_cont <- tmle(Y = Y,
                  A = A,
                  W = W,
                  family = "gaussian",            # continuous outcome
                  Q.SL.library = Qlib,
                  g.SL.library = glib,
                  verbose = TRUE)

# Quick summary
print(summary(tmle_cont))
# Extract ATE (difference in adjusted means: E[Y|A=1] - E[Y|A=0])
# tmle_cont$estimates contains entries; the ATE entry is typically:
if(!is.null(tmle_cont$estimates$ATE)) {
  ate_est <- tmle_cont$estimates$ATE$psi
  ate_var <- tmle_cont$estimates$ATE$var.psi
  ate_se  <- sqrt(ate_var)
  ate_ci  <- ate_est + c(-1,1) * qnorm(0.975) * ate_se
  cat("Adjusted mean difference (cases - control):", round(ate_est,4), "\n")
  cat("95% CI: [", round(ate_ci[1],4), ",", round(ate_ci[2],4), "]\n")
} else {
  # some tmle versions name it differently; printing object helps inspect
  print("No ATE element found in tmle_cont$estimates; inspect summary(tmle_cont) to find psi and var.")
}

# -----------------------------
# Option B: If FM is skewed / count => log-transform TMLE
# -----------------------------
# Transform outcome
Ylog <- log(Y + 1)   # add 1 to handle zeros

tmle_log <- tmle(Y = Ylog,
                 A = A,
                 W = W,
                 family = "gaussian",            # regression on transformed outcome
                 Q.SL.library = Qlib,
                 g.SL.library = glib,
                 verbose = TRUE)

print(summary(tmle_log))
if(!is.null(tmle_log$estimates$ATE)) {
  psi_log <- tmle_log$estimates$ATE$psi    # difference in mean(log(Y+1))
  var_log <- tmle_log$estimates$ATE$var.psi
  se_log  <- sqrt(var_log)
  ci_log  <- psi_log + c(-1,1) * qnorm(0.975) * se_log
  cat("Adjusted difference on log-scale (cases - control):", round(psi_log,4), "\n")
  cat("95% CI (log-scale): [", round(ci_log[1],4), ",", round(ci_log[2],4), "]\n")
  # Back-transform interpretation: approx multiplicative effect on (Y+1)
  ratio_est <- exp(psi_log)
  ratio_ci  <- exp(ci_log)
  cat("Approx. ratio of geometric means (cases / control) on (FM+1) scale:", round(ratio_est,3), "\n")
  cat("95% CI for ratio: [", round(ratio_ci[1],3), ",", round(ratio_ci[2],3), "]\n")
}

# -----------------------------
# Diagnostics & tips
# -----------------------------
# 1) Check positivity: ensure both groups exist across covariate patterns (no perfect separation).
# 2) Try different SuperLearner libraries (SL.gam, SL.ranger, etc.) if installed for robustness.
# 3) If you prefer TMLE using a poisson/quasi-poisson model directly, consider tmle3 or use GLM-based Q/g that
#    include poisson link — classic tmle() primarily supports gaussian/binomial families for the final targeting step.
# 4) Check model fit and influence function diagnostics in the tmle object (residuals, clever covariate).

```


#### TMLE

Using TMLE (Takes 3'):

```{r eval=FALSE}
tmle_output <- tmle(FM_data_enrollment$FM, as.integer(FM_data_enrollment$group == "HFMD"),
                    select(FM_data_enrollment, -c(FM, group)))
```

```{r eval=FALSE}
summary(tmle_output)
```

```{r eval=FALSE}
tmle_output2 <- tmle(FM_data_enrollment$FM, as.integer(FM_data_enrollment$group == "HFMD"),
                     select(FM_data_enrollment, -c(FM, group)),
                     Qform = FM_data_enrollment$FM ~ A + W1 + W2 + W3,
                     gform = A ~ W1 + W2 + W3)
```

```{r}
tmle2 <- function(x, ...) {
  Y <- x[[1]]
  A <- x[[2]]
  W <- x[, -(1:2)]
  covariables <- paste(names(W), collapse = "+")
  tmle(Y, A, W,
       Qform = as.formula(paste("Y ~ A +", covariables)),
       gform = paste("A ~ ", covariables), ...)
}
```

```{r}
tmle3 <- function(x, ...) {
  Y <- x[[1]]
  A <- x[[2]]
  W <- x[, -(1:2)]
  covariables <- paste(names(W), collapse = "+")
  tmle(Y, A, W,
       Qform = Y ~ A + Gender + age + MomEdu + stunting,
       gform = A ~ Gender + age + MomEdu + stunting, ...)
}
```

takes 3':

```{r eval=FALSE}
a <- FM_data_enrollment |> 
  mutate(across(group, ~ as.integer(.x == "HFMD"))) |> 
  tmle2()
```

```{r eval=FALSE}
system.time(
b <- FM_data_enrollment |> 
  mutate(across(group, ~ as.integer(.x == "HFMD"))) |> 
  tmle3()
)
```

```{r eval=FALSE}
x <- FM_data_enrollment |> 
  mutate(across(group, ~ as.integer(.x == "HFMD")),
         across(age, as.numeric),
         across(where(is.character), as.factor),
         across(where(is.logical), as.integer))



Y <- x$FM
A <- x$group
W <- x[, -(1:2)]

output <- tmle(Y, A, W, Qform = Y ~ A + Gender + age + MomEdu + stunting, gform = A ~ Gender + age + MomEdu + stunting)
```

