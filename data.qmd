---
title: "08RS data"
number-sections: true
format:
  html:
    toc: true
    toc-depth: 4
editor: source
editor_options: 
  chunk_output_type: console
#bibliography: references.bib
#csl: the-american-naturalist.csl
---

```{r include = FALSE, eval = FALSE}
knitr::purl("data.qmd", "tmp.R", documentation = FALSE)
source("tmp.R")
file.remove("tmp.R")

add_nojekyll <- function() {
  file <- ".nojekyll"
  file.create(file)
  gert::git_add(file)
  gert::git_commit("Adding the .nojekyll file")
  gert::git_push()
}
```

```{r include = FALSE}
setHook("plot.new", NULL, action = "replace")

par2 <- function(...) par(..., mgp = c(1.5, .5, 0), bty = "n")

knitr::knit_hooks$set(
  margin = function(before, options, envir) {
    if (before) par2(plt = c(.105, .97, .15, .95)) else NULL
  })

eps <- 1
knitr::opts_chunk$set(margin    = TRUE,
                      fig.retina = 2,
                      fig.align  = "center",
                      fig.height = eps * 5, # default is 5
                      fig.width  = eps * 7) # default is 7
```


## Constants

The path to the data folder on the local computer:

```{r}
root <- "~/Library/CloudStorage/OneDrive-OxfordUniversityClinicalResearchUnit"
data_folder <- paste0(root, "/GitHub/choisy/08RS/")
``` 

```{r include = FALSE}
path2cache <- paste0(stringr::str_replace(getwd(), Sys.getenv("HOME"), root),
                     "/cache/")
if (! dir.exists(path2cache)) dir.create(path2cache)
make_path <- function(x) paste0(path2cache, x)
file_exists <- function(x) file.exists(make_path(x))
readRDScache <- function(x) readRDS(make_path(x))
saveRDScache <- function(object, file) saveRDS(object, make_path(file))
```


## Packages

Required packages:

```{r}
required <- c("readxl", "purrr", "dplyr", "magrittr", "tidyr", "anthro", "twang",
              "cobalt", "survey", "tmle", "RColorBrewer")
```

Installing those that are not installed yet:

```{r}
to_install <- required[! required %in% installed.packages()[,"Package"]]
if (length(to_install)) install.packages(to_install)
```

Loading some packages for interactive use:

```{r message = FALSE}
library(dplyr)
library(purrr)
library(stringr)
library(tidyr)
library(twang)
library(cobalt)
library(survey)
library(tmle)
```


## Functions

A tuning of the `readxl::read_excel()` function:

```{r}
read_excel2 <- function(file, ...) readxl::read_excel(paste0(data_folder, file), ...)
```

A function that reads all the tabs of an excel file in the data folder `data_folder`
defined above:

```{r}
read_excel_file <- function(file) {
  sheets_names <- readxl::excel_sheets(paste0(data_folder, file))
  sheets_names |>
    map(~ read_excel2(file, .x)) |> 
    setNames(sheets_names)
}
```

A function that remove some slots of a list, by names:

```{r}
remove_slots <- function(lst, slt) {
  lst[setdiff(names(lst), slt)]
}
```

A function that extracts some variables of some slots of a list `x` of data frames:

```{r}
get_vars <- function(sel, x) {
  x |> 
    magrittr::extract(names(sel)) |>
    map2(sel, ~ select(.x, !!!.y))
}
```

The variables in questions are defined in the named list `sel` of character vectors.
The names of this list should be among the names of `x` and the character vectors of
each slots should be among the names of the columns of the data frames in the
corresponding slots. A function that patches data values from the data frame `patch`
into the data frame `df`, using the `key` variable as a common key between the two data
frames:

```{r}
patch <- function(patch, df, key) {
  ref <- df[, key]
  sel <- df[[key]] %in% patch[[key]]
  tmp <- df[sel, ]
  tmp_names <- names(tmp)
  tmp <- bind_cols(patch, tmp[, setdiff(tmp_names, names(patch))])[tmp_names]
  df[! sel, ] |> 
    bind_rows(tmp) |> 
    left_join(x = ref, y = _, by = key)
}
```

A function that renames a column of a data frame:

```{r}
rename2 <- function(df, newname, oldname) {
  df_names <- names(df)
  df_names[which(df_names == oldname)] <- newname
  setNames(df, df_names)
}
```

A function that splits a data frame into a list of data frames:

```{r}
split_df <- function(x, n_rows) {
  nb_rows <- nrow(x)
  split(x, gl(nb_rows %/% n_rows + (nb_rows %% n_rows > 0), n_rows, nb_rows))
}
```

A function that appends a data frame `x` with `n` rows of values `v`:

```{r}
append_dataframe <- function(x, n = 1, v = 0) {
  1:ncol(x) |>
    map(~ rep(v, n)) |> 
    as.data.frame() |> 
    setNames(names(x)) |>  
    (\(y) bind_rows(x, y))()
}
```

A function that applies `append_dataframe()` to the last slot of a list `x` of data
frame so that the number of rows of the data frame in the last slot is equal to the
number of rows of the data frame in the first lost:

```{r}
append_last <- function(x, v = 1) {
  nb_slots <- length(x)
  nb_rows1 <- nrow(x[[1]])
  nb_rows2 <- nrow(x[[nb_slots]])
  if (nb_rows2 < nb_rows1) {
    x[[nb_slots]] <- append_dataframe(x[[nb_slots]], nb_rows1 - nb_rows2, v)
  }
  x
}
```

A tuning of the `image()` function:

```{r}
image2 <- function(x, y, z, ...) image(x, y, t(z[nrow(z):1, ]), ...)
```

A function that adds a zero y value to both ends of a data frame with two columns `x`
and `y`:

```{r}
adding_zero_ys <- function(x) {
  x <- as_tibble(x[c("x", "y")])
  x <- bind_rows(head(x, 1), x, tail(x, 1))
  x$y[c(1, nrow(x))] <- 0
  x
}
```

A function that converts a 1-row matrix with columns names into a named vector:

```{r}
as_vector <- function(x) setNames(as.vector(x), colnames(x))
```

A tuning of the `coef()` function:

```{r}
coef2 <- function(x) last(coef(x))
```

A tuning of the `confint()` function:

```{r}
confint2 <- function(x) as_vector(last(suppressMessages(confint(x))))
```

A function that retrieve the p value of the last parameter of a model:

```{r}
get_p <- function(x) last(as.vector(coefficients(summary(x))))
```

A tuning of the `svyglm()` function:

```{r}
svyglm2 <- function(formula, data, w) {
  data |>
    svydesign(ids = ~1, weights = w, data = _) |> 
    svyglm(formula, design = _)
}
```

Shortcut to `magrittr::extract(...)`:

```{r}
mextract  <- function(...) magrittr::extract(...)
```

Shortcut to `magrittr::extract2(...)`:

```{r}
mextract2 <- function(...) magrittr::extract2(...)
```

A function that pads density coordinates with y zero value points:

```{r}
pad_density <- function(x) {
  tmp <- x$x
  x$x <- c(tmp[1], tmp, last(tmp))
  x$y <- c(0, x$y, 0)
  x
}
```

A tuning of the `density()` function:

```{r}
density2 <- function(...) {
  density(...) |> 
    pad_density()
}
```

A tuning of the `polygon()` function:

```{r}
polygon2 <- function(...) polygon(..., border = NA)
```

A function that computes the range of a variable `var` across a list `x` of data
frames:

```{r}
range2 <- function(x, var) {
  x |> 
    map(mextract2, var) |> 
    range()
}
```

## Saras' CSV file

```{r, message = FALSE}
saras <- readr::read_csv(paste0(root, "/GitHub/choisy/08RS/complete data including ",
                                "all withdrawals_updated26_3_21.csv"))
```

```{r}
select(saras, waste, visitM, ddifENB, ddifEN, FUP, FUP1)
```

```{r}
table(saras$waste)
```


## Raw data

### 08RS CRF

Loading the data from CliRes:

```{r}
CRF08RS <- read_excel_file("6-11-2024-CTU08RS_Data.xlsx")
```

The names of the data frames in CliRes and in Saras' code, with definitions:

```{r}
# CliRes        Saras           Definition
# ------------------------------------------------------------------
# ENROL         data_EN         enrollment
# HIST          data_HIST       history at enrollment
# CONHIST       CONHIST         contact history at enrollment
# EXAM          data_EX         symptoms and signs at enrollment
# LAB           data_LAB        lab results at admission
# NEU           data_NEU        neurological exam
# DAILY         data_Daily      daily review
# MED           data_MED        medications
# DEVSOCSED     data_DEV        development and socio-economic data
# DISC          data_DISC       discharge summary
# FUP           data_FUP        first follow-up day 7-10
# FUP_II        data_FUP6m      first follow-up month 6
# FUP_III       data_FUP18m     first follow-up month 18
# NEURO         data_NEURO      neurological assessment
# ABC           data_MABC       movement ABC-2
```

The 08RS CRF dictionary:

```{r}
CRF_dict <- list(
  devsocsed = list(MomEdu = c("Never been to school",
                              "Attended some primary school",
                              "Completed primary school (5th gr)",
                              "Completed lower secondary school (9th gr)",
                              "Completed higher secondary school (12th gr)",
                              "Completed university/college degree",
                              "Completed postgraduate degree"),
                   Toilet = c("Own flush toilet",
                              "Shared flush toilet",
                              "Traditional pit toilet",
                              "Ventilation improved pit toilet",
                              "No facility/bush/field",
                              "None of above"),
                   Water  = c("Private tap",
                              "Public standpipe",
                              "Bottled water",
                              "Well in own residence",
                              "Public well",
                              "Rain water",
                              "Spring",
                              "River/lake/pond", NA,
                              "None of the above")),
  disc = list(GradeHFMD   = c("grade 1",
                              "grade 2a",
                              "grade 2b(1)",
                              "grade 2b(2)",
                              "grade 3",
                              "grade 4",
                              "Not Applicable"),
              Outcome     = c("Full recovery without complication",
                              "Incomplete recovery",
                              "Transferred to another hospital",
                              "Taken home without approval",
                              "Death",
                              "Discharged to die")))
```

Selection of variables from the 08RS CRF:

```{r}
selection08RS <- list(ENROL     = c("ParNo", "DateEnrol", "Gender", "DateBirth"),
                      HIST      = c("ParNo", "DateIllness", "DateAdmHTD", "DateAdmHTD",
                                    "DateAdmHosp", "HFMDToday", "HFMDAdmitted"),
                      EXAM      = c("ParNo", "headCircumference", "height", "weigh"),
                      DEVSOCSED = c("ParNo", "MomEdu", "Toilet", "Refrigerator",
                                    "AirConditioner", "Motorbike", "Water"),
                      DISC      = c("ParNo", "DateDisc", "GradeHFMD", "TreatSepsis",
                                    "Outcome", "Seizure", "Hypertonicity", "LimbPara",
                                    "CNP", "DiapWeak", "Trache", "Nasotube",
                                    "BehaveChange"))
```


### 02EI CRF

```{r}
CRF02EI <- read_excel_file("6-11-2024-CTU02EI_Data.xlsx")
```

Selection of variables from the 02EI CRF:

```{r}
selection02EI <- list(Demo  = c("studyCode", "height", "weight"),
                      Hist  = c("studyCode", "IllnessDate"),
                      Disch = c("studyCode", "seizures", "tracheostomy",
                                "muscleStength", "limbParalysing", "nerveParalysing"))
```


### PCR data

```{r message = FALSE}
PCR <- "03EI-08RS PCR-Seq result.xlsx" |>
  read_excel2("08RS") |> 
  select(ID, `OUCRU RESULT`) |> 
  mutate(across(ID, as.numeric)) |> 
  na.exclude()
```


### MRI data

```{r, message = FALSE}
MRI <- paste0(root, "/GitHub/choisy/08RS/part_dataMRIentry_28AUG15_errorcor.csv") |>
  readr::read_csv() |> 
  rename(ID = code) |> 
  select(ID, Final, Acute) |> 
  mutate(across(c("Final", "Acute"), ~ .x == "Yes"))
```

What is the difference between `Final` and `Acute`?

```{r}
filter(MRI, Final != Acute)
```


## Children data

### 08RS, PCR, MRI

The case and control groups:

```{r}
groups <- c(rep("HFMD", 299), rep("control", 200),
            rep("HFMD", 200), rep("control", 299))
```

First recoding of variables:

```{r}
recoding1 <- function(x) {
  x |>
    mutate(across(Gender, ~ c("male", "female")[.x]),
           across(starts_with("Date"), as.Date),
           across(c("Refrigerator", "AirConditioner",
                    "Motorbike", "TreatSepsis"), ~ .x < 2))
}
```

Second recoding of variables:

```{r}
recoding2 <- function(x) {
  x |>
    mutate(across(HFMD, ~ CRF_dict$disc$GradeHFMD[.x]),
           across(MomEdu, ~ CRF_dict$devsocsed$MomEdu[.x]),
           across(Toilet, ~ CRF_dict$devsocsed$Toilet[.x]),
           across(Water, ~ CRF_dict$devsocsed$Water[.x]),
           across(Outcome, ~ CRF_dict$disc$Outcome[.x]))
}
```

Selecting and recoding the variables from the 08RS CRF, and assigning to case or
control:

```{r}
children <- selection08RS |> 
  remove_slots("ABC") |> 
  get_vars(CRF08RS) |> 
  reduce(left_join, by = "ParNo") |> 
  rowwise() |> 
  mutate(HFMD = max(across(c(HFMDToday, HFMDAdmitted, GradeHFMD)))) |> #takes max grade
  ungroup() |> 
  recoding1() |> 
  recoding2() |>
  mutate(ID    = as.numeric(str_remove(ParNo, "^.*-")),
         group = groups[ID]) |> 
  left_join(MRI, "ID") |> 
  left_join(PCR, "ID") |> 
  rename(PCR = `OUCRU RESULT`) |> 
  select(-HFMDToday, -HFMDAdmitted, -GradeHFMD, -ID) |> 
  select(ParNo, Gender, DateBirth, DateIllness, DateAdmHosp,
         DateAdmHTD, DateEnrol, DateDisc, everything()) |> 
  arrange(ParNo)
```

### Patching 02EI CRF

Conversion of IDs between 02EI and 08RS:

```{r}
(ID_conv <- tibble(s02EI = paste0("03-0", c(paste0("0", c(1, 3:9)), c("11", "13"))),
                   s08RS = paste0("03-0", c(43, 52:56, 60, 62, 78, 79))))
```

Patching the data values from the 02EI CRF:

```{r}
children <- selection02EI |> 
  get_vars(CRF02EI) |> 
  reduce(left_join, by = "studyCode") |> 
  mutate(across(IllnessDate, as.Date),
         across(c("seizures", "tracheostomy", "muscleStength", "limbParalysing",
                  "nerveParalysing"), ~ .x < 2)) |> 
  rename(ParNo         = studyCode,
         weigh         = weight,
         DateIllness   = IllnessDate,
         Seizure       = seizures,
         Trache        = tracheostomy,
         Hypertonicity = muscleStength,
         LimbPara      = limbParalysing,
         CNP           = nerveParalysing) |> 
  filter(ParNo %in% ID_conv$s02EI) |> 
  mutate(across(ParNo, ~ unname(with(ID_conv, setNames(s08RS, s02EI))[.x]))) |> 
  patch(children, "ParNo")
```

### Stunt and waste

```{r}
children <- children |> 
  mutate(age = DateEnrol - DateBirth,
         z   = anthro::anthro_zscores(c(male = 1, female = 2)[Gender],
                                      as.numeric(age),
                                      weight = weigh,
                                      lenhei = height)[c("zlen", "zwfl")]) |> 
  unnest(z) |> 
  mutate(stunting = zlen < -2,
         wasting  = ifelse(zwfl < -3, "severe",
                           ifelse(zwfl < -2, "moderate", "no"))) |> 
  select(- zlen, - zwfl)
```

### Missing values

A function that computes the numbers and percentages of missing values per variable:

```{r}
number_of_NA <- function(x) {
  x |> 
    select(- group) |> 
    map_dfr(~ sum(is.na(.x))) |> 
    pivot_longer(! ParNo, names_to = "variable", values_to = "number_of_NA") |> 
    mutate(percentage_of_NA = round(100 * number_of_NA / n)) |> 
    select(- ParNo)
}
```

Let's look at the missing values among cases:

```{r}
cases <- filter(children, group == "HFMD")
n <- nrow(cases)

cases |> 
  number_of_NA() |> 
  print(n = Inf)
```

And among controls:

```{r}
controls <- filter(children, group == "control")
n <- nrow(controls)

controls |> 
  number_of_NA() |> 
  filter(percentage_of_NA < 100) |> 
  print(n = Inf)
```

Retrieving the height, weight and stunt data from Saras' CSV file:

```{r}
saras_stunt <- saras |> 
  select(code, WEIGHT, HEIGHT, headCircumference, stunt, waste) |> 
  unique() |> 
  mutate(ParNo = paste0(ifelse(code < 923, "03-", "05-"), sprintf("%03d", code)))
```

Merging with our children data frame:

```{r}
comparing_data <- children |> 
  select(ParNo, height, weigh, stunting) |> 
  left_join(saras_stunt, "ParNo")
```

Checking that children codes match:

```{r}
setdiff(saras_stunt$ParNo, comparing_data$ParNo)
setdiff(comparing_data$ParNo, saras_stunt$ParNo)
```

```{r}
plot_comp <- function(...) {
  plot(..., col = adjustcolor(4, .15), pch = 19,
       xlab = "CRF", ylab = "Saras'", asp = 1)
  abline(0, 1, col = 2)
}
```

Comparing height data:

```{r fig_comparisons, fig.width = 6, fig.height = 3}
opar <- par(mfrow = 1:2, pty = "s", plt = rep(c(.2, .93), 2), bty = "o")

comparing_data |> 
  filter_out(is.na(height)) |> 
  with(plot_comp(height, HEIGHT))
mtext("heights (cm)", line = .2)

comparing_data |> 
  filter_out(is.na(weigh)) |> 
  with(plot_comp(weigh, WEIGHT))
mtext("weights (kg)", line = .2)

par(opar)
```



## M-ABC data

```{r}
ABC <- CRF08RS$ABC |> 
  select(ParNo, DateTested, ends_with("ISS")) |> 
  mutate(across(starts_with("Date"), as.Date)) |> 
  arrange(ParNo, DateTested)
```

Of note, here

* `MD` stands for manual dexterity,
* `AC` stands for aiming and catching and
* `BAL` stands for balance.

```{r}
ABC |> 
  na.exclude()
```


## Bayley data

Loading the data from CliRes:

```{r}
Bayley0 <- read_excel_file("12-9-2025-Bayley_v3_P1_Data.xlsx")
```

The tabs that we are interested in are the following:

* **CS:** cognitive scale
* **RC:** receptive communication (language scale)
* **EC:** expressive communication (language scale)
* **FM:** fine motor (motor scale)
* **GM:** gross motor (motor scale)

```{r}
Bayley_tabs <- c("CS", "RC", "EC", "FM", "GM")
```

Let's generate the data frame from these tabs:

```{r}
common_variables1 <- c("PARNO", "DATETESTED")
common_variables2 <- c(common_variables1, "SCALESCORE")

Bayley<- Bayley_tabs |> 
  map(~ c(common_variables2, .x)) |> 
  setNames(Bayley_tabs) |> 
  get_vars(Bayley0) |> 
  map2(paste0("SCALESCORE_", Bayley_tabs), rename2, "SCALESCORE") |> 
  reduce(left_join, by = c("PARNO", "DATETESTED")) |> 
  mutate(across(starts_with("DATE"), as.Date)) |> 
  rename(ParNo = PARNO) |> 
  mutate(across(ParNo, ~ stringr::str_remove(.x, "08RS_")))
```


## Time points

A function that generates the time points:

```{r}
make_time_points <- function(x) {
  children |> 
    select(ParNo, DateEnrol, DateDisc) |> 
    left_join(x, "ParNo") |> 
    mutate(time_diff = DateTested - DateEnrol,
           time1 = 0, time2 = 6, time3 = 18, # in months
           across(c(time1, time2, time3), ~ as.numeric(abs(time_diff - 30 * .x)))) |> 
    rowwise() |> 
    mutate(min_delay = min(across(c(time1, time2, time3)))) |> 
    ungroup() |> 
    mutate(time_point = ifelse(min_delay == time1,
                               "enrollment", ifelse(min_delay == time2,
                                                    "6 months", "18 months")))
}
```

A function that gets the IDs of children with duplicated assessments:

```{r}
get_IDs_with_duplicated <- function(x) {
  x |> 
    filter(! is.na(time_point)) |> 
    group_by(ParNo) |> 
    group_modify(~ .x |>
                   group_by(time_point) |>
                   tally()) |> 
    ungroup() |> 
    filter(n > 1) |> 
    pull(ParNo) |> 
    unique()
}
```

A function that uses the previous two to generate the data with duplicated assessments:

```{r}
show_duplicated_assessments <- function(x) {
  data_with_time_points <- make_time_points(x)
  IDs_with_duplicates <- get_IDs_with_duplicated(data_with_time_points)
  filter(data_with_time_points, ParNo %in% IDs_with_duplicates)
}
```


### M-ABC data

```{r}
ABC |>
  show_duplicated_assessments() |> 
  writexl::write_xlsx("M-ABC2.xlsx")
```

Here all the duplicates are complete. We'll simply keep all the earlier ones:

```{r}
ABC2 <- ABC |> 
  make_time_points() |>
  arrange(ParNo, time_point, min_delay) |> 
  group_by(ParNo, time_point) |> 
  group_modify(~ head(.x, 1)) |> 
  ungroup() |> 
  select(-DateEnrol, -DateDisc, -min_delay, - time_diff, -time1, -time2, -time3) |> 
  rename(Date_ABC = DateTested)
```


### Bayley data

```{r}
Bayley <- rename(Bayley, DateTested = DATETESTED)

Bayley |>
  show_duplicated_assessments() |> 
  writexl::write_xlsx("Bayley2.xlsx")
```

This shows that

* there is one and only one complete measurement per time point
* the complete measurement is always the earlier one, except for patient `03-514`

In consequence, we decide to simply filter out all the incomplete duplicates:

```{r}
Bayley2 <- Bayley |> 
  make_time_points() |>
  group_by(ParNo, time_point) |> 
  group_modify(~ {if (nrow(.x) > 1) return(na.exclude(.x)); .x }) |> 
  ungroup() |> 
  select(-DateEnrol, -DateDisc, -min_delay, - time_diff, -time1, -time2, -time3) |> 
  rename(Date_Bayley = DateTested)
```


### Merging

Merging the M-ABC and Bayley data:

```{r}
followups <- full_join(ABC2, Bayley2, c("ParNo", "time_point"))
```


### Visualization

A function that prepend all the data frames of a list `x` of data frames with `n`
columns of the `v` values:

```{r}
prepend_white <- function(x, n, v) {
  nbrows <- nrow(x[[1]])
  white_space <- v |> 
    rep(n * nbrows) |> 
    matrix(nbrows) |> 
    as.data.frame()
  map(x, ~ cbind(white_space, .x))
}
```

A function that (i) splits the data frame `x` into a list of data frame of `n` rows 
(except possibly for the last slot), (ii) prepends each of these data frames with `wc`
columns of 1s, and (iii) concatenate all these data frames side by side into a matrix:

```{r}
side_by_side <- function(x, n, wc) {
  x |>
    select(-ParNo) |>
    split_df(n) |> 
    append_last() |>
    prepend_white(wc, 1) |> 
    reduce(cbind) |> 
    as.matrix()
}
```

A tuning of `image2()`:

```{r}
image3 <- function(x, col_no, col_yes) {
  image2(0:ncol(x), 0:nrow(x), x, axes = FALSE, ann = FALSE, col = c(col_no, col_yes))
}
```

The function that plots the heatmap:

```{r}
heatmap2 <- function(x, nbrow = 45, nb_wc = 2,
                     col_Bayley = adjustcolor("red", .3),
                     col_ABC    = adjustcolor("blue", .3),
                     col_NA     = adjustcolor("white", 0),
                     col_lines  = "white") {
# plotting M-ABC data:
  tmp <- x |> 
    select(-Date_Bayley) |> 
    pivot_wider(names_from = time_point, values_from = Date_ABC) |> 
    side_by_side(nbrow, nb_wc)
  image3(tmp, col_NA, col_Bayley)
  
# adding Bayley data:
  par(new = TRUE)
  x |> 
    select(-Date_ABC) |> 
    pivot_wider(names_from = time_point, values_from = Date_Bayley) |> 
    side_by_side(nbrow, nb_wc) |> 
    image3(col_NA, col_ABC)

# adding separation lines:
  abline(v = 0:ncol(tmp), col = col_lines)
  abline(h = 0:nbrow, col = col_lines)

# adding children IDs:
  ids <- str_remove(unique(x$ParNo), "^.*-")
  sel <- 1:length(ids)
  by <- 3 + nb_wc
  ncol_tmp <- ncol(tmp)
  nbcol <- ncol_tmp / by
  xs <- rep(seq(1, ncol_tmp, by), each = nbrow)[sel]
  ys <- rep(rev(1:nbrow - .5), nbcol)[sel]
  text(xs, ys, ids)

# adding time points:
  xx <- seq(1 + nb_wc, ncol_tmp, by) - .5
  mtext(rep(c("e", "1", "2"), nbcol)[sel], at = sort(c(xx, xx + 1, xx + 2)))
}
```

An overview of the M-ABC and Bayley data for all the children and the 3 time points:

```{r fig_followup_data_availability, fig.height = 11, fig.width  = 14}
expand_grid(ParNo      = unique(followups$ParNo),
            time_point = c("enrollment", "6 months", "18 months")) |> 
  left_join(followups, c("ParNo", "time_point")) |> 
  select(ParNo, time_point, starts_with("Date")) |> 
  mutate(across(starts_with("Date"), ~ as.numeric(! is.na(.x)) + 1)) |> 
  heatmap2()
```

where blue is where the Bayley data are available, red is where the M-ABC data are
available, purple is where both data are available and white is where none of the data
are available.


## Analysis

### HFMD vs controls

From here we work with 2 data frames: `children` that contains the children
information, and `followups` that contains the follow-up data. Note that height and
weight (and consequently stunting) is missing for about 22% of children:

```{r}
children |> 
  select(group, age, MomEdu, Gender, stunting) |> 
  map_int(~ sum(is.na(.x)))
```

Some common code:

```{r}
cols <- c(2, 4)
adjcol <- function(...) adjustcolor(..., alpha = .3)

barplot2 <- function(height, x) {
  barplot(height, names.arg = x, beside = TRUE, ylab = "proportion",
          col = adjcol(rev(cols)))
}

add_legend1 <- function(where = "topright") {
  legend(where, legend = c("control", "HFMD"), fill = adjcol(rev(cols)), bty = "n")
}
```

Let's look at the age distribution of the controls and HFMD cases:

```{r fig_age_distribution}
tmp <- children |>
  mutate(across(age, ~ as.numeric(.x) / 30)) |> 
  group_by(group) |> 
  group_map(~ .x |> pull(age) |> density(from = 0))

tmp |> 
  map(~ .x |> unclass() |> magrittr::extract(c("x", "y")) |> as_tibble()) |> 
  bind_rows() |> 
  map(range) |> 
  with(plot(NA, xlim = x, ylim = y, xlab = "age (months)", ylab = "density"))

tmp |> 
  walk2(cols, ~ polygon(adding_zero_ys(.x), col = adjcol(.y), border = NA))

add_legend1()
```

Let's now look at the level of the mother's education:

```{r fig_mom_edu}
edu_order <- c("Never been to school", "Attended some primary school",
               "Completed primary school (5th gr)",
               "Completed lower secondary school (9th gr)",
               "Completed higher secondary school (12th gr)",
               "Completed university/college degree", "Completed postgraduate degree")

children |> 
  with(table(MomEdu, group)) |>
  prop.table(2) %>%
  `[`(edu_order, ) |> 
  t() |> 
  barplot2(c("none", "some", "5th grd", "9th grd", "12th grd", "college", "postgrad"))

add_legend1()
```

Stunt and gender:

```{r fig_sex_stunt}
children |> 
  select(group, Gender, stunting) |> 
  na.exclude() |> 
  group_by(group) |> 
  group_split() |> 
  map(~ .x |> group_by(Gender, stunting) |> tally() |> ungroup()) |> 
  reduce(left_join, c("Gender", "stunting")) |> 
  select(starts_with("n")) |> 
  as.matrix() |> 
  prop.table(2) |> 
  t() %>%
  `[`(2:1, ) |> 
  barplot2(rep(c("female", "male"), each = 2))

mtext(rep(c("non-stunt", "stunt"), 2), 1, 1.5, at = c(2, 5, 8, 11))
add_legend1()
```

### Propensity scores

The covariates:

```{r}
covariables <- select(children, ParNo, Gender, age, MomEdu, stunting, group)
```

The formula:

```{r}
ps_formula <- group ~ Gender + age + MomEdu + stunting
```

A function that generates a data set for a given response variable at a given time
point:

```{r}
make_data <- function(response, timepoint) {
  followups |> 
    filter(time_point == timepoint) |> 
    select(ParNo, all_of(response)) |> 
    na.exclude() |> 
    left_join(covariables, "ParNo") |> 
    select(-ParNo) |> 
    select(all_of(response), group, everything()) |> 
    na.exclude()
}
```

A function that generates weights from a logistic regression:

```{r}
logistic_ps <- function(data) {
  data |>
    mutate(across(group, ~ .x == "HFMD"),
           weights = ps_formula |>
             glm(binomial, data = pick(everything())) |> 
             predict(type = "response") %>%
             { ifelse(group, 1, . / (1 - .)) }) |> 
    pull(weights)
}
```

A function that generates weights from the `twang` package:

```{r}
twang_ps <- function(data, ...) {
  data |> 
    mutate(across(group, ~ as.integer(group == "HFMD")),
           across(where(~ is.character(.x) | is.logical(.x)), as.factor),
           across(age, as.numeric)) |> 
    as.data.frame() |> 
    ps(ps_formula, data = _, estimand = "ATT", stop.method = "es.mean",
       verbose = FALSE, ...) |> 
    get.weights("es.mean")  
}
```

A function that computes the TMLE:

```{r}
default_libs <- c("SL.glm", "SL.glmnet", "SL.mean", "SL.gam")

tmle2 <- function(data, response, family = "gaussian",
                  Qlib = default_libs, glib = default_libs, ...) {
  data |> 
    select(Gender, age, MomEdu, stunting) |> 
    mutate(across(where(~ is.character(.x) | is.logical(.x)), as.factor),
           across(age, as.numeric)) |>
    tmle(data[[response]], as.integer(data$group == "HFMD"), W = _, family = family,
         Q.SL.library = Qlib, g.SL.library = glib) |> 
    mextract2(c("estimates", "ATT")) |> 
    mextract(c("psi", "CI", "pvalue")) |> 
    unlist() |> 
    setNames(c("cf_tm", "2.5 %tm", "97.5 %tm", "p_tm"))
}
```

A function that computes balance statistics for diagnostic of the propensity scores:

```{r}
bal_tab <- function(data, w) {
  data |> 
    mutate(across(group, ~ .x == "HFMD")) |> 
    bal.tab(ps_formula, data = _, weights = w, s.d.denom = "treated")
}
```

A function that retrieve the balance adjustments for diagnostic of the propensity
scores:

```{r}
get_diff <- function(x) x$Balance$Diff.Adj
```

A function that produce the maximum values of the balance adjustments for diagnostic of
the propensity scores:

```{r}
get_max_diff <- function(data, w) {
  data |> 
    bal_tab(w) |> 
    get_diff() |> 
    max()
}
```

A function that generate the formula of the model with the response `y`:

```{r}
reformulate2 <- function(y) {
  reformulate(c("Gender", "age", "MomEdu", "stunting", "group"), y)
}
```

A function that processes the output of a model in the `pipeline()` function that
follows:

```{r}
process_model <- function(x, model, nm) {
  x |> 
    mutate(!!paste0("cf_", nm) := map_dbl({{ model }}, coef2),
           ci                   = map({{ model }}, confint2)) |>   
    unnest_wider(ci) |> 
    rename_with(~ paste0(.x, nm), ends_with("%")) |> 
    mutate(!!paste0("p_", nm) := map_dbl({{ model}}, get_p))
}
```

The pipeline:

```{r}
pipeline <- function() {
  expand_grid(response  = c("MD1ISS", "MD2ISS", "MD3ISS", "AC1ISS", "AC2ISS",
                            "BAL1ISS", "BAL2ISS", "BAL3ISS",
                            "CS", "RC", "EC", "FM", "GM"),
              timepoint = c("enrollment", "6 months", "18 months")) |> 
    mutate(dataset = map2(response, timepoint, ~ make_data(.x, .y)),
           ctable  = map(dataset, ~ as.vector(table(.x$group)))) |> 
    filter(map_lgl(ctable, ~ length(.x) > 1)) |> 
    mutate(ctable = map(ctable, ~ setNames(.x, c("control", "HFMD")))) |> 
    unnest_wider(ctable) |> 
    filter(HFMD > 3) |> 
    mutate(dataset = map(dataset,
                         ~ mutate(.x, ow = logistic_ps(pick(everything())),
                                      tw = twang_ps(pick(everything())),
                                      t2 = twang_ps(pick(everything()),
                                                    n.trees = 5000,
                                                    interaction.depth = 2))),
           formula = map(response, ~ reformulate("group", .x)),
           glm0 = map2(formula,  dataset, ~ glm(.x, data = .y)),
           glm1 = map2(response, dataset, ~ glm(reformulate2(.x), data = .y)),
           m_ow = map2(formula,  dataset, ~ svyglm2(.x, .y, ~ow)),
           m_tw = map2(formula,  dataset, ~ svyglm2(.x, .y, ~tw)),
           m_t2 = map2(formula,  dataset, ~ svyglm2(.x, .y, ~t2))) |> 
    process_model(glm0, "l0") |> 
    process_model(glm1, "l1") |> 
    process_model(m_ow, "ow") |> 
    process_model(m_tw, "tw") |> 
    process_model(m_t2, "t2") |> 
# 6 - TMLE:           
    mutate(tmle = map2_dfr(dataset, response, tmle2)) |> 
    unnest_wider(tmle)
}
```

A function that computes the diagnostic metrics for a dataset `x` and for the
propensity score weight `psw`:

```{r}
diagnostic_metrics <- function(x, psw) {
  y <- x[[psw]]
  y <- c(max = max,
         mea = mean,
         med = median,
         ess = function(x) sum(x)^2 / sum(x^2)) |>
    map_dfc(~ .x(y)) |> 
    mutate(dif = abs(mea - med),
           bal = get_max_diff(x, psw))
  names(y) <- paste0(psw, "_", names(y))
  y
}
```

A function that runs `diagnostic_metrics()` on all the datasets of an output `x` of the
`pipeline()` function, and for the propensity score weight `psw`:

```{r}
diagnostic_ps <- function(x, psw) {
  x |> 
    select(response, timepoint, control, HFMD, dataset) |> 
    mutate(diag = map(dataset, diagnostic_metrics, psw)) |> 
    unnest_wider(diag) |> 
    mutate(n = control + HFMD) |> 
    select(-c(dataset, control, HFMD))
}
```

Running the pipeline (takes 2'):

```{r eval = FALSE}
output <- pipeline()
```

```{r include = FALSE}
if (file_exists("output.rds")) {
  output <- readRDScache("output.rds")
} else {
  output <- pipeline()
  saveRDScache(output, "output.rds")
}
```

Let's compare the p values:

```{r}
output |> 
  select(response, timepoint, control, HFMD, starts_with("p_")) |> 
  mutate(across(starts_with("p"), ~ round(.x, 3))) |> 
  print(n = Inf) 
```

Let's look at the estimates:

```{r}
output |> 
  select(response, timepoint, control, HFMD, starts_with("cf")) |> 
  mutate(across(starts_with("cf"), ~ round(.x, 2))) |> 
  print(n = Inf) 
```

Computing the diagnostic metrics for all the propensity score weights:

```{r}
c("ow", "tw", "t2") |>
  map(diagnostic_ps, x = output) |> 
  walk(print, n = Inf)
```

**Interpretations:**

* covariates balance < 0.1 is good. Values between 0.1 and 0.2 are indicative of
moderate imbalance. Values above 0.2 are a problem.
* weights should not be too high.
* weights distribution should not be too heavy right tail.
* mean an median of weights should not be too different.
* effective sample size should not be too different from real sample size (not less
than 50% of original sample size).
* effective sample size should not be lower than the number treated.
* max weight should not be much higher than 10 to 20 times the median weight.

### Responses

A function that plots the density of the response for a given data set (where the
response is the first variable of input `x` data frame):

```{r}
plot_density1 <- function(x) {
  x |> 
    pull(1) |> 
    density2() |> 
    (\(x) {
      plot(x, type = "n", xlab = "response", ylab = "density")
      polygon2(x, col = 4)
    })()
}
```

This function splits the response (i.e. first variable) of the `x` data frame into
control and disease:

```{r}
split2control_disease <- function(x) {
  c("control", "HFMD") |> 
    set_names() |> 
    map(~ x |> filter(group == .x) |> pull(1))
}
```

This function does the same as `plot_density1()` but for the control and infected
separately:

```{r}
plot_density2 <- function(x) {
  x |> 
    split2control_disease() |> 
    map(density2) |> 
    (\(x) {
      plot(NA, xlim = range2(x, "x"), ylim = range2(x, "y"),
           xlab = "response", ylab = "density")
      walk2(x, adjustcolor(c(4, 2), .2), ~ polygon2(.x, col = .y))
    })()
}
```

Let's look at the distribution of the responses:

```{r fig_responses_distribution1, fig.width = 7, fig.height = 7.5, margin1 = FALSE, margin2 = TRUE}
opar <- par(mfrow = c(6, 4))
output |> 
  pull(dataset) |> 
  walk(plot_density1)
par(opar)
```

Let's look at the distribution of the responses, distinguishing control (in blue) and
infected patients (red):

```{r fig_responses_distribution2, fig.width = 7, fig.height = 7.5, margin1 = FALSE, margin2 = TRUE}
opar <- par(mfrow = c(6, 4))
output |> 
  pull(dataset) |> 
  walk(plot_density2)
par(opar)
```


### Ploting effects

The methods and their color code:

```{r}
methods <- c("l0", "l1", "ow", "tw", "t2")
cols <- RColorBrewer::brewer.pal(length(methods), "Set1")
```

The variables that have only 1 time point:

```{r}
(var1timepoint <- output |> 
  group_by(response) |> 
  tally() |> 
  filter_out(n > 1) |> 
  pull(response))
```

And this time point is 18 months:

```{r}
output |> 
  filter(response %in% var1timepoint) |> 
  pull(timepoint) |> 
  unique()
```

A function that adds the legend to a plot:

```{r}
add_legend2 <- function() {
  legend("topright", legend = methods, col = cols, lwd = 1, pch = 19, bty = "n")
}
```

The function that plots the effects of disease on the scores:

```{r}
plot_effects <- function(x) {
  x |>
    map2(seq(-.2, .2, .1), ~ mutate(.x, x = x + .y)) |> 
    map2(cols, ~ mutate(.x, col = .y)) |> 
    bind_rows() |> 
    with({
      plot(x, y, ylim = c(min(l), max(u)), col = col, axes = FALSE, xlab = NA,
           pch = 19, ylab = "effect of disease on score")
      abline(h = 0)
      arrows(x, l, x, u, .05, 90, 3, col)
      })
  axis(2)
}
```

Plotting the variables that are available at 18 months only:

```{r fig_M_ABC}
prepare_data1 <- function(method, data) {
  data |> 
    select(response, ends_with(method), -starts_with(c("p", "m"))) |> 
    mutate(x = 1:n()) |> 
    setNames(c("response", "y", "l", "u", "x"))
}

methods |> 
  map(prepare_data1, filter(output, response %in% var1timepoint)) |> 
  plot_effects()

add_legend2()
mtext(var1timepoint, 1, at = seq_along(var1timepoint))
```

The time points:

```{r}
timepoints <- c("enrollment", "6 months", "18 months")
```

The function that plots 3 time points for 1 variables, and 5 methods:

```{r}
prepare_data2 <- function(method, data) {
  data |> 
    select(timepoint, ends_with(method), -starts_with(c("p", "m"))) |> 
    mutate(x = 1:n()) |> 
    setNames(c("timepoint", "y", "l", "u", "x"))
}

plot_1_variable <- function(var) {
  methods |> 
    map(prepare_data2, filter(output, response == var)) |> 
    plot_effects()

  mtext(var, line = -1, at = 1.5)
  mtext(timepoints, 1, at = seq_along(timepoints), cex = 2 / 3)
}
```

Plotting the other variables:

```{r fig_Bayley, fig.width = 7, fig.height = 7.5, margin1 = FALSE, margin2 = TRUE}
opar <- par(mfrow = c(3, 2))
output |> 
  pull(response) |> 
  unique() |> 
  setdiff(var1timepoint) |> 
  walk(plot_1_variable)
add_legend2()
par(opar)
```




